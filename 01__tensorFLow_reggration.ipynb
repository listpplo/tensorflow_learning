{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/listpplo/tensorflow_learning/blob/main/01__tensorFLow_reggration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za1tObb1yDxJ"
      },
      "source": [
        "## **Neural Network Regression with TensorFlow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ8AvgwsyDxL"
      },
      "outputs": [],
      "source": [
        "    \"\"\"import tensorflow\"\"\"\n",
        "    import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "risgiMHryDxM",
        "outputId": "fd4d7d3b-e1e4-42c7-a4b5-364b3deb7940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.2958901  0.648312   0.09882522]\n",
            " [0.6331359  0.9217684  0.6511483 ]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.51106966 0.30130255 0.12281215]\n",
            " [0.26824522 0.0577774  0.64826405]], shape=(2, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Setiing the seed makes the tensor generation predictable\n",
        "tf.random.set_seed(43)\n",
        "print(tf.random.uniform(shape = (2,3),seed = 23))\n",
        "print(tf.random.uniform(shape = (2,3),seed =23))     \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdZuVmk1yDxN"
      },
      "source": [
        "> Regression means simply prediciting the number\n",
        "\n",
        "> Regression : A regression is a statistical technique that relates a dependent variable to one or more independent (explanatory) variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2rHRWz-yDxN"
      },
      "source": [
        "input_features --> Machine Learning Algorithm --> Output_Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iR6tiQqyDxO"
      },
      "source": [
        "Determining the price of the house for the given data\n",
        "\n",
        "\n",
        "For Input_Features = [ BedRooms , BathRooms , Garages]     ---> Shape = 3\n",
        "\n",
        "\n",
        "For Output_Features = [Price]                              ---> Shape = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAhrsAXXyDxO"
      },
      "source": [
        "# Anantomy of Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd51Fa-RyDxO"
      },
      "source": [
        "Input_Features  ---> *Input_Layers* (Data gets input here) ---> *Hidden Layers* (Learns patterns in the the data) ---> *Output layer* (Output learned representation or predicition probability)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYvLVAH5yDxO"
      },
      "source": [
        "# Crating a Regression data for our project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13ID7XbyDxO"
      },
      "source": [
        "> **Introduction to Regression with Neural network in TensorFLow**\n",
        "\n",
        "Trying to predict the numerical values based on some other combination of variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm0jXk9RyDxO",
        "outputId": "66ad9dd0-61c7-4a53-edff-9aa8c781e506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "# checking the version of TensorFLow \n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "gI5uPG-byDxP",
        "outputId": "e88fff34-34e4-478b-fbf0-e2df539e14c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13\n",
            "13\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating features \n",
        "X = np.array([7,6,6,5,4,3,4,5,6,7,8,9,10])\n",
        "\n",
        "print(len(X))\n",
        "\n",
        "# Creating labels\n",
        "Y = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
        "\n",
        "print(len(Y))\n",
        "\n",
        "# ploting X and Y\n",
        "plt.scatter(X,Y);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_JA0fNsyDxP"
      },
      "source": [
        "> **Input and Output shapes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKSRWiCzyDxP",
        "outputId": "ed8f9f84-bba2-4de1-e8bf-562270584bc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedRoom', b'BathRoom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a demo tensor for our house price prediction problem \n",
        "\n",
        "house_info = tf.constant([\"bedRoom\",\"BathRoom\",\"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info,house_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCOfHbgryDxQ",
        "outputId": "6ba2d4c9-7a66-43b2-a293-f24dac69ce44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((13,), (13,))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Input_Shape = X.shape\n",
        "Output_Shape = Y.shape\n",
        "\n",
        "Input_Shape, Output_Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTkgLihTyDxQ"
      },
      "source": [
        "> For this problem we are looking for scaler i.e. 0 dimensional tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAytBoWxyDxQ",
        "outputId": "9f65efad-0d7b-4f56-a496-f80f0cbfccc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(13,), dtype=int64, numpy=array([ 7,  6,  6,  5,  4,  3,  4,  5,  6,  7,  8,  9, 10])>,\n",
              " <tf.Tensor: shape=(13,), dtype=int64, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])>)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turning the numpy arrays into tensors\n",
        "\n",
        "X = tf.constant(X)\n",
        "Y = tf.constant(Y)\n",
        "\n",
        "X,Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J037vOsMyDxQ"
      },
      "source": [
        "### Steps in modelling in tensorflow\n",
        "\n",
        "1. Creating a model --> Defining the input, Output and hidden layers in deep learning model.\n",
        "\n",
        "2. Compiling a model --> defining a **loss function**(How accurate our model is),a **optimizer**(tells out model how to impeove the learning patterns) and a **evualtion metrics**(How we can inteprete the performanace of our model).\n",
        "\n",
        "3. FItting the model --> letting the model try to find patterns between X and Y(Features and lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7DfYAv0yDxQ"
      },
      "source": [
        "> When We create the model we always compile it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dayqom5vyDxQ",
        "outputId": "6f8cd1ac-602f-41f4-c771-5e4c85153972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 4.2352 - mae: 4.2352\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.1279 - mae: 4.1279\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.0206 - mae: 4.0206\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9134 - mae: 3.9134\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8061 - mae: 3.8061\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6988 - mae: 3.6988\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5915 - mae: 3.5915\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.4871 - mae: 3.4871\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4251 - mae: 3.4251\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.3630 - mae: 3.3630\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd625a530a0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setting the random seed \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. creating the model using TensorFlow\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)   # Dense function gives the number of neurons in the layer\n",
        "\n",
        "])\n",
        "\n",
        "#2. compiling the model\n",
        "model.compile(loss =tf.keras.losses.mae,    # mae  --> Mean absolute error\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "\n",
        "model.fit(tf.expand_dims(X,axis = -1),Y, epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPhQKhwk10dh",
        "outputId": "6a698327-743e-4bcb-cb5c-dcf79e0ed1b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(13,), dtype=int64, numpy=array([ 7,  6,  6,  5,  4,  3,  4,  5,  6,  7,  8,  9, 10])>,\n",
              " <tf.Tensor: shape=(13,), dtype=int64, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking X and Y\n",
        "X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkrF5mKU0ovC",
        "outputId": "67a74c3b-07a0-4a60-cf77-a794eef3cff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 109ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[8.749829]], dtype=float32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# try and predict with our model\n",
        "y_pred = model.predict([10])\n",
        "y_pred\n",
        "\n",
        "# The value we get are far off from the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8RV3RED2Edh"
      },
      "source": [
        "# Improving Our model\n",
        "\n",
        "We can improve our model by :  \n",
        "1. **Creating a model** -->  add more layers , increasing the number of hidden units(all called neurons) within each of the hidden layers, change activation of each layers. \n",
        "\n",
        "2. **Compiling the model** --> We can change the optimizing function or perhaps the **learning rate** of the optimizing stage.\n",
        "\n",
        "3. **Fitting the model** --> We can make make the model train for longer or give the model more data to train upon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBZxza72uAO"
      },
      "source": [
        "Metrices --> Humar interperatble model representing that how weel the model is doing. \n",
        "\n",
        "Epochs --> how may times the model will go through the traning.\n",
        "\n",
        "Loss --> How wrong the model predictions are compared to the truth tables(Lower the better)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrKcWBxg3nlP"
      },
      "source": [
        "> We define a smaller model to make sure that our data works, This will help us to save time before going to a laregr model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkdm4NiR6iEO",
        "outputId": "c2de2aaa-a430-473d-d195-f5e3713a8210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 537ms/step - loss: 3.9741 - mae: 3.9741\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8668 - mae: 3.8668\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7595 - mae: 3.7595\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6523 - mae: 3.6523\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5450 - mae: 3.5450\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4514 - mae: 3.4514\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3893 - mae: 3.3893\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3273 - mae: 3.3273\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2652 - mae: 3.2652\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2031 - mae: 3.2031\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1410 - mae: 3.1410\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0790 - mae: 3.0790\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0169 - mae: 3.0169\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9548 - mae: 2.9548\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8928 - mae: 2.8928\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8307 - mae: 2.8307\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7686 - mae: 2.7686\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7065 - mae: 2.7065\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6445 - mae: 2.6445\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5824 - mae: 2.5824\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5203 - mae: 2.5203\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4583 - mae: 2.4583\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3986 - mae: 2.3986\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3640 - mae: 2.3640\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3294 - mae: 2.3294\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2948 - mae: 2.2948\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2830 - mae: 2.2830\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2820 - mae: 2.2820\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2810 - mae: 2.2810\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2800 - mae: 2.2800\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2790 - mae: 2.2790\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2780 - mae: 2.2780\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2793 - mae: 2.2793\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2804 - mae: 2.2804\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2794 - mae: 2.2794\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2784 - mae: 2.2784\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2777 - mae: 2.2777\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2807 - mae: 2.2807\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2797 - mae: 2.2797\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2787 - mae: 2.2787\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2777 - mae: 2.2777\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2796 - mae: 2.2796\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2801 - mae: 2.2801\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2791 - mae: 2.2791\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2781 - mae: 2.2781\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2780 - mae: 2.2780\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2804 - mae: 2.2804\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2794 - mae: 2.2794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2784 - mae: 2.2784\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2774 - mae: 2.2774\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2799 - mae: 2.2799\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2798 - mae: 2.2798\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2788 - mae: 2.2788\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2778 - mae: 2.2778\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2783 - mae: 2.2783\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2801 - mae: 2.2801\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2791 - mae: 2.2791\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2781 - mae: 2.2781\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2771 - mae: 2.2771\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2802 - mae: 2.2802\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2795 - mae: 2.2795\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2785 - mae: 2.2785\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2775 - mae: 2.2775\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2786 - mae: 2.2786\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2798 - mae: 2.2798\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2788 - mae: 2.2788\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2778 - mae: 2.2778\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2771 - mae: 2.2771\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2802 - mae: 2.2802\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.2792 - mae: 2.2792\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2782 - mae: 2.2782\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2772 - mae: 2.2772\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2789 - mae: 2.2789\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2796 - mae: 2.2796\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2785 - mae: 2.2785\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2775 - mae: 2.2775\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2774 - mae: 2.2774\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2799 - mae: 2.2799\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2789 - mae: 2.2789\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2779 - mae: 2.2779\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2769 - mae: 2.2769\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2792 - mae: 2.2792\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2793 - mae: 2.2793\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2783 - mae: 2.2783\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2772 - mae: 2.2772\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2777 - mae: 2.2777\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2796 - mae: 2.2796\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2786 - mae: 2.2786\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2776 - mae: 2.2776\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2766 - mae: 2.2766\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2795 - mae: 2.2795\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2790 - mae: 2.2790\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2780 - mae: 2.2780\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2769 - mae: 2.2769\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2780 - mae: 2.2780\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2793 - mae: 2.2793\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2783 - mae: 2.2783\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2773 - mae: 2.2773\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2764 - mae: 2.2764\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2797 - mae: 2.2797\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6259d9c70>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's Rebuid our model\n",
        "\n",
        "# 1. create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling the model\n",
        "model.compile(loss = \"mae\",\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. fitting the model\n",
        "\n",
        "model.fit(tf.expand_dims(X, -1),Y, epochs = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkR9jqZUo-51"
      },
      "source": [
        "> Just changing the epochs we have improved the accuracy of the model.\n",
        "\n",
        ">previous loss = 6.475 --> current loss = 2.27"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIee27XG8tio",
        "outputId": "25e8488e-d533-421b-91fc-68c1ceeedb8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(13,), dtype=int64, numpy=array([ 7,  6,  6,  5,  4,  3,  4,  5,  6,  7,  8,  9, 10])>,\n",
              " <tf.Tensor: shape=(13,), dtype=int64, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])>)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The data I provided \n",
        "\n",
        "X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3bPU6Ij6yL8",
        "outputId": "1672f820-8058-4eda-f184-56fcfe22f63e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[4.0664673]], dtype=float32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict([3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFZ7EUFC8cI3"
      },
      "source": [
        ">The system returns the value which is just equal to the current value minus the error "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTfcDpQjqCbo"
      },
      "source": [
        "> **Now we can see the effect of changing the number of neurons inside the neural network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15N8-DwIqjwa",
        "outputId": "1e773f8d-9419-4df7-b51d-d79dff913d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 385ms/step - loss: 3.4034 - mae: 3.4034\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3413 - mae: 3.3413\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2792 - mae: 3.2792\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2172 - mae: 3.2172\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1551 - mae: 3.1551\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0930 - mae: 3.0930\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.0310 - mae: 3.0310\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9689 - mae: 2.9689\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9068 - mae: 2.9068\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8448 - mae: 2.8448\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7827 - mae: 2.7827\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7206 - mae: 2.7206\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6585 - mae: 2.6585\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5965 - mae: 2.5965\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5344 - mae: 2.5344\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4723 - mae: 2.4723\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4103 - mae: 2.4103\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3611 - mae: 2.3611\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3264 - mae: 2.3264\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2918 - mae: 2.2918\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2837 - mae: 2.2837\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2827 - mae: 2.2827\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2817 - mae: 2.2817\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2807 - mae: 2.2807\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2797 - mae: 2.2797\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2793 - mae: 2.2793\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2820 - mae: 2.2820\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2810 - mae: 2.2810\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2800 - mae: 2.2800\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2790 - mae: 2.2790\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2812 - mae: 2.2812\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2814 - mae: 2.2814\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2804 - mae: 2.2804\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2794 - mae: 2.2794\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2796 - mae: 2.2796\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2817 - mae: 2.2817\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2807 - mae: 2.2807\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2797 - mae: 2.2797\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2787 - mae: 2.2787\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2814 - mae: 2.2814\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2811 - mae: 2.2811\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2801 - mae: 2.2801\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2791 - mae: 2.2791\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2799 - mae: 2.2799\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2814 - mae: 2.2814\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2804 - mae: 2.2804\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2794 - mae: 2.2794\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2784 - mae: 2.2784\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2817 - mae: 2.2817\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2808 - mae: 2.2808\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2798 - mae: 2.2798\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2788 - mae: 2.2788\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2802 - mae: 2.2802\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2811 - mae: 2.2811\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2801 - mae: 2.2801\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2791 - mae: 2.2791\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2787 - mae: 2.2787\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2815 - mae: 2.2815\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2805 - mae: 2.2805\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2795 - mae: 2.2795\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2785 - mae: 2.2785\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2805 - mae: 2.2805\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2808 - mae: 2.2808\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2798 - mae: 2.2798\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2788 - mae: 2.2788\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2790 - mae: 2.2790\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2812 - mae: 2.2812\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2802 - mae: 2.2802\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2792 - mae: 2.2792\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2782 - mae: 2.2782\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2808 - mae: 2.2808\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2805 - mae: 2.2805\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2795 - mae: 2.2795\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2785 - mae: 2.2785\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2793 - mae: 2.2793\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2809 - mae: 2.2809\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2799 - mae: 2.2799\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2789 - mae: 2.2789\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2779 - mae: 2.2779\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2811 - mae: 2.2811\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2802 - mae: 2.2802\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2792 - mae: 2.2792\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2782 - mae: 2.2782\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2796 - mae: 2.2796\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2806 - mae: 2.2806\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2796 - mae: 2.2796\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2786 - mae: 2.2786\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2780 - mae: 2.2780\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2810 - mae: 2.2810\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2800 - mae: 2.2800\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2789 - mae: 2.2789\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2779 - mae: 2.2779\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2798 - mae: 2.2798\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2803 - mae: 2.2803\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2793 - mae: 2.2793\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2783 - mae: 2.2783\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2783 - mae: 2.2783\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2807 - mae: 2.2807\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2797 - mae: 2.2797\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2786 - mae: 2.2786\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd68e457760>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model with more number of neurons \n",
        "\n",
        "# 1. Creating the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),  \n",
        "])\n",
        "\n",
        "# 2. compiling the model\n",
        "model.compile(loss = \"mae\",\n",
        "              optimizer = tf.keras.optimizers.SGD(lr = 0.01),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X,-1),Y, epochs= 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIrcmMgerkha"
      },
      "source": [
        "> We can see by increasing the layers the the  my mean absolute error is increasing in this case ,so every change in the model dosen't lead to improvement in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCP7JYPjuoST"
      },
      "source": [
        "The metrices we see are not really representative of what the mdoel is going to predict."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfRNNZO1tK_n"
      },
      "source": [
        "> We predict the accuracy of the model by using to predict the data that the model have not seen till now.\n",
        "\n",
        "> That is by dividing the data into two groups one for traning and one for predcicting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfjFznk4uHbX"
      },
      "source": [
        "**Common way of improving the model :**\n",
        "1. By adding more layers \n",
        "2. increasing the number of hidden layers\n",
        "3. Changing the activation function\n",
        "4. Changing the optimizer function \n",
        "5. Changing the learning rate \n",
        "6. Fitting on more data \n",
        "7. Fitting to longer (larger number of epochs)\n",
        "\n",
        "the learning rate is the most important hyper parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t7x08Y_kGCl"
      },
      "source": [
        "## **Evaluating a Model**\n",
        "```\n",
        "In practice a typical workflow :\n",
        "Build a model --> fit it --> evaluate it --> tweak a model --> fit it --> evaluate it --> tweak a model --> evaluate it.......```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yosZ-YkMl3uF"
      },
      "source": [
        "Hyperparameter are the nobs that we can adjust to optimize the learnig of the model.\n",
        "\n",
        "Parameter are those patterns that the model learn from the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iYBBky3nNn8"
      },
      "source": [
        "When it comes to evaluation ... there are 3 words to memorise :\n",
        "\n",
        "> \"Visualise, visualise , visualise\"\n",
        "\n",
        "This to visulaise :\n",
        "1. The data that we are working with \n",
        "2. model it self -- what does our model look like\n",
        "3. The traning of a model - how does the model perform while it learns ?\n",
        "4. The predictions of the model - how the model predict against the ground truth.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXjFJnEFoIqX",
        "outputId": "ccbc5303-f864-4e5f-be11-3874f27af61f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# making a bigger dataset\n",
        "x= tf.range(-100,100,4)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVO-ZxvmoRsm",
        "outputId": "735c3615-2b23-4981-dc62-9ff7f7a9fc58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# making the label for our model\n",
        "\n",
        "y= x+10\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "h1U0-fyLocfa",
        "outputId": "ab82db88-73c2-44c9-c510-f6346824090c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fd625902310>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#ploting the data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpkkjTPTolo4"
      },
      "source": [
        "### The concept of three sets \n",
        "\n",
        "* Traning set -- The model learns on this tyoe of data about 70-80% of the data \n",
        "\n",
        "* Validation set -- The model get tuned on this set , which is typically 10-15% of the data available.\n",
        "\n",
        "* Test Set -- The model get evaluated on this set , this set is typically 10-15 percent of the total data available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZnOxO01p00o",
        "outputId": "2937ca7d-9607-4141-b6ef-50ead3200c44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the length of how many data we are working on\n",
        "\n",
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZus0CufqTcc",
        "outputId": "f87feb63-f00e-42b7-afc5-0b6e0c5a41da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-100  -96  -92  -88  -84  -80  -76  -72  -68  -64  -60  -56  -52  -48\n",
            "  -44  -40  -36  -32  -28  -24  -20  -16  -12   -8   -4    0    4    8\n",
            "   12   16   20   24   28   32   36   40   44   48   52   56], shape=(40,), dtype=int32)\n",
            "\n",
            "tf.Tensor([60 64 68 72 76 80 84 88 92 96], shape=(10,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into train and test sets \n",
        "x_train = x[:40]       # We want the first 40 data as we are working with 50 data \n",
        "y_train = y[:40]\n",
        "\n",
        "x_test = x[40:]        # the last 10 traning samples\n",
        "y_test= y[40:]\n",
        "\n",
        "print(x_train)\n",
        "print(\"\")\n",
        "print(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "tiajx_BwqzB0",
        "outputId": "6a826883-2260-480e-cf32-a087b25c5fd7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from prompt_toolkit.shortcuts.dialogs import Label\n",
        "# Visualising the data \n",
        "\n",
        "plt.scatter(x_train,y_train, label =\" Traning data\")    #learn learning data  on\n",
        "plt.scatter(x_test, y_test, label = \" Test data\") #predict on the testing data\n",
        "\n",
        "plt.legend();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4Lmllo2r7sq"
      },
      "outputs": [],
      "source": [
        "# make a model to predict the above value\n",
        "\n",
        "# 1. creating a model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(lr = 0.01),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "#3 fitting the data \n",
        "#model.fit(tf.expand_dims(x_train,-1),y_train, epochs =100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV0vyik8tviH"
      },
      "source": [
        "> ## Visualising the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "rfo4jCZwt0Hs",
        "outputId": "81903244-f4a9-4f09-dc2d-9313291af2bb"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2867\u001b[0m     \"\"\"\n\u001b[1;32m   2868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2869\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   2870\u001b[0m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvQMmmMscclT"
      },
      "outputs": [],
      "source": [
        "# Making another model with input shape\n",
        "tf.random.set_seed(42)\n",
        "#1. making a model with input shape \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape = [1] ),   # the input shape will be 1 because we are taking one number for  predicting one number\n",
        "    tf.keras.layers.Dense(4)])\n",
        "\n",
        "#2. compiling the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "#Fully connected layers is also known as Dense layers\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIUOoaAwd5bz",
        "outputId": "d2ed4da1-beb3-4d11-c118-a49388447b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u9OMslZiwjy"
      },
      "source": [
        "* Total number parameters are the total number of relations that my model will try to learn form the data.\n",
        "* Trananble parameters --> These are parameters (pattersns) the model can update as it trains.\n",
        "* Non tainable para --> These are the parameters that aren't updated during the traning (These come from the transfer learning i.e. the previously learned patters)\n",
        "\n",
        "\n",
        "\n",
        "📚 **Resource** --> MIT introduction to deep learning \n",
        "\n",
        "**Extercise** -- > change the number of hidden layers in the dense layers and observe the change in the learning parametrs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buRGj2pdlCng"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train,epochs=100,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFKVDBegnOcH"
      },
      "outputs": [],
      "source": [
        "# we can use plot model function to visualise the model\n",
        "\n",
        "form tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0NfNyrM1nYZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d789b3-71bc-4318-959c-742aea863342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104]\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 33.9620 - mae: 33.9620\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.6422 - mae: 26.6422\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.1127 - mae: 21.1127\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.0398 - mae: 17.0398\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7540 - mae: 12.7540\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1164 - mae: 10.1164\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7942 - mae: 7.7942\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1602 - mae: 6.1602\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3247 - mae: 3.3247\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9748 - mae: 2.9748\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4326 - mae: 3.4326\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8448 - mae: 3.8448\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.6501 - mae: 2.6501\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.9612 - mae: 3.9612\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9210 - mae: 3.9210\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1654 - mae: 2.1654\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3565 - mae: 3.3565\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0163 - mae: 4.0163\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8854 - mae: 3.8854\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8010 - mae: 3.8010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5981 - mae: 3.5981\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9198 - mae: 3.9198\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9043 - mae: 2.9043\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3400 - mae: 5.3400\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1040 - mae: 2.1040\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2915 - mae: 3.2915\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9730 - mae: 3.9730\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1093 - mae: 6.1093\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.0977 - mae: 3.0977\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.0053 - mae: 4.0053\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.7524 - mae: 2.7524\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6480 - mae: 3.6480\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.7139 - mae: 2.7139\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.4473 - mae: 2.4473\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0312 - mae: 4.0312\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.1992 - mae: 2.1992\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8456 - mae: 3.8456\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5556 - mae: 2.5556\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2325 - mae: 3.2325\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5824 - mae: 4.5824\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0757 - mae: 3.0757\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1691 - mae: 2.1691\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2405 - mae: 2.2405\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9856 - mae: 2.9856\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.9286 - mae: 2.9286\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6986 - mae: 3.6986\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.8697 - mae: 2.8697\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8869 - mae: 3.8869\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2588 - mae: 3.2588\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7827 - mae: 3.7827\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.4018 - mae: 4.4018\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.0225 - mae: 2.0225\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.1104 - mae: 2.1104\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9869 - mae: 1.9869\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.4633 - mae: 2.4633\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2034 - mae: 3.2034\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3342 - mae: 4.3342\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9945 - mae: 3.9945\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2947 - mae: 3.2947\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3605 - mae: 4.3605\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.1564 - mae: 3.1564\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.0506 - mae: 6.0506\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.9320 - mae: 2.9320\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8644 - mae: 3.8644\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9475 - mae: 3.9475\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.8144 - mae: 2.8144\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9318 - mae: 1.9318\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5855 - mae: 2.5855\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2944 - mae: 4.2944\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9402 - mae: 2.9402\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3012 - mae: 5.3012\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.4006 - mae: 2.4006\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5495 - mae: 2.5495\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3988 - mae: 3.3988\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3728 - mae: 3.3728\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.2811 - mae: 3.2811\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9893 - mae: 2.9893\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.4813 - mae: 3.4813\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9983 - mae: 3.9983\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7116 - mae: 2.7116\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.5282 - mae: 2.5282\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4305 - mae: 4.4305\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3647 - mae: 3.3647\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.6495 - mae: 4.6495\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2486 - mae: 2.2486\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0950 - mae: 3.0950\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.1454 - mae: 4.1454\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1777 - mae: 3.1777\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5934 - mae: 3.5934\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.1350 - mae: 4.1350\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1453 - mae: 3.1453\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3731 - mae: 2.3731\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.4148 - mae: 2.4148\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3608 - mae: 3.3608\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.6635 - mae: 4.6635\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1123 - mae: 3.1123\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.8132 - mae: 3.8132\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.3506 - mae: 2.3506\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1382 - mae: 2.1382\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.1881 - mae: 5.1881\n",
            "************************************************************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.engine.sequential.Sequential"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "x = list()\n",
        "#creating data for the modle to fit \n",
        "for i in range(0,100):\n",
        "  x.append(i)\n",
        "\n",
        "\n",
        "y = list()\n",
        "for i in range(0,len(x)):\n",
        "  y.append(x[i]+ 5)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print()\n",
        "print()\n",
        "# seprating the data sets into traning data and testing data\n",
        "#traning data\n",
        "x_train =tf.constant(x[:40])\n",
        "y_train =tf.constant(y[:40])\n",
        "\n",
        "#testing data\n",
        "x_test = tf.constant(x[41:])\n",
        "y_test = tf.constant(y[41:]) \n",
        "\n",
        "#1 creating the model \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[1]),\n",
        "    tf.keras.layers.Dense(3)       #we need to define the shapes for the model to get build properly\n",
        "])\n",
        "\n",
        "#2. compiling the model\n",
        "\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "              metrics = [\"mae\"])\n",
        "#3 fitting the model \n",
        "\n",
        "model.fit(x_train, y_train, epochs = 100)\n",
        "\n",
        "print(\"************************************************************\")\n",
        "type(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SEwzh6WbRow",
        "outputId": "30c633e2-3ee4-4bb9-8146-815174c36028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By increasing the learning rate the efectiveness of the modle decreases , the modle ties to learn a lot faster Nd overshoots the predicted values."
      ],
      "metadata": {
        "id": "Ccnc3EwI_yS0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c85b68248aa2fc15fe6a356e23a8710a52b493a26cd9eca9fc59a0b7f9da1ae5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}